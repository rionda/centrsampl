\section{Preliminaries}\label{sec:prelims}
In this section we introduce the definitions and lemmas that we will use to
develop and analyze our results in the remainder of the paper.

\subsection{Graphs and betweenness centrality}\label{sec:graphprelims}
Let $G=(V,E)$ be a graph, where $E\subseteq V\times V$, with $n=|V|$ vertices
and $m=|E|$ edges. Each edge
$e\in E$ has a non-negative (\XXX necessary?
\MR) weight $\mathsf{w}(e)$. The graph $G$ can be directed or undirected. We assume
that $G$ is connected and that there are no self-loops and no multiple edges
between a pair of vertices. Given a pair of vertices $(u,v)\in V\times V$,
$u\neq v$, a \emph{path $p_{uv}\subseteq V$ from $u$ to $v$} is an ordered sequence of
vertices $p_{uv}=(w_1,\dotsc,w_{|p_{uv}|})$ such that $w_1=u$, $w_{|p_{uv}|}=v$ and
for each $1\le i < |p_{uv}|$, $(w_i,w_{i+1})\in E$. The \emph{length}
$\ell(p_{uv})$ of a path $p_{uv}$ from $u$ to $v$ is the sum of the weights of
the edges composing the path:
$\ell(p_{uv})=\sum_{i=1}^{|p_{uv}|-1}\mathsf{w}((w_i,w_{i+1}))$. We denote with
$|p_{uv}|$ the number of vertices composing the path and call this the
\emph{size of the path $p_{uv}$}. Note that if the weights are not all unitary,
it is not necessarily true that $\ell(p_{uv})=|p_{uv}|-1$.

Given two vertices $(u,v)\in V\times V$, the \emph{shortest path distance}
$\sigma_{uv}$ between $u$ and $v$ is the length of a path with minimum length
between $u$ and $v$, among all paths between $u$ and $v$. If there is no path
between $u$ and $v$, $\sigma_{uv}=0$. We call a path between $u$ and $v$ with
length $\sigma_{uv}$ a \emph{shortest path between $u$ and $v$}. There can be
multiple shortest paths between $u$ and $v$ and we denote the set of these paths
as $\mathcal{S}_{uv}$. If $\sigma_{u,v}=0$, then $\mathcal{S}_{uv}=\emptyset$.
We denote with $\mathbb{S}_G$ the union of all the $\mathcal{S}_{uv}$, for all
$(u,v)\in V\times V$: 
\[ \mathbb{S}_G=\bigcup_{(u,v)\in V\times V}\mathcal{S}_{uv}\enspace.\]

We now define a characteristic quantity of a graph that we will use throughout
the paper.
\begin{definition}\label{def:vertexdiam}
  Given a graph $G=(V,E)$, the \emph{vertex-diameter $\Delta_G$ of $G$} is the
  maximum size of a shortest path between a pair of vertices of $V$:
  \[
  \Delta_G = \max\left\{|p| ~:~ p\in \mathbb{S}_G\right\}\enspace.\]
\end{definition}
If all the edge weights are unitary, then $\Delta_G$ is equal to
$\mathsf{diam}(G)+1$, where $\mathsf{diam}(G)$ is the number of edges composing the
longest shortest path in $G$.
Given a vertex $v$, let $\mathcal{T}_v\subseteq\mathbb{S}_G$ be the set of all
shortest paths that $v$ belongs to:
\[
\mathcal{T}_v=\{p\in\mathbb{S}_G ~:~ v\in p\}\enspace.
\]
In this work we are interested in the \emph{betweenness centrality} of the
vertices of a graph.
\begin{definition}\label{def:betwenness}
  Given a graph $G=(V,E)$, the \emph{betweenness centrality of a vertex $v\in
  V$} is defined as
  \[
  %\betw(v)=\sum_{(u,w)\in V\times
  %V}\sum_{p\in\mathcal{S}_{uw}}\frac{\mathds{1}_{\mathcal{T}_v}(p)}{|\mathcal{S}_{uw}|}\enspace.
  %\betw(v)=\sum_{p_{uw}\in\mathbb{S}_G}\frac{\mathds{1}_{\mathcal{T}_v}(p)}{|\mathcal{S}_{uw}|}\enspace.
  \betw(v)=\sum_{p_{uw}\in\mathbb{S}_G}\frac{\mathds{1}_{\mathcal{T}_v}(p)}{|\mathcal{S}_{uw}|}=\sum_{p_{uw}\in\mathcal{T}_v}\frac{1}{|\mathcal{S}_{uw}|}\enspace.
  \]
  It is easy to see that $n\le b(v)\le\binom{n}{2}$. \XXX Check original def \MR 
\end{definition} 

\XXX reference \MR presented an algorithm to compute the betweenness centrality for
all $v\in V$ in time $O(n^2)$. 

\subsection{Vapnik-Chervonenkis dimension}\label{sec:prelvcdim}
The Vapnik-Chernovenkis (VC) dimension of a class of subsets defined
on a set of points is a measure of the complexity or expressiveness of such
class~\citep{VapnikC71}. Given a probability distribution on the set of points,
a finite bound on the VC-dimension of the class of subsets implies a bound on
the number of random samples required to approximate the probability of each
subsets its empirical average. We outline here some basic definitions and
results and refer the reader to the works of~\citet[Sect.~14.4]{AlonS08} and
\citet[Sect.~3]{BoucheronBL05} for an introduction of VC-dimension and a survey
of recent developments. 
%~\citet[Sect.~12.4]{DevroyeGL96},
%\citet[Sect.~3]{BoucheronBL05}, \citet[Sect.~14.4]{AlonS08}, and
%\citet{Vapnik99} for more details on VC-dimension.

Let $D$ be a domain and $\range$ be a collection of subsets from $D$. We call
$\range$ a \emph{range set on $D$}.
Given $B\subseteq D$, the \emph{projection of $\range$ on $B$} is the set 
$P_\range(B)=\{ B\cap A ~:~ A\in\range\}$. We say that the set $B$ is
\emph{shattered} by $\range$ if $P_\range(B)=2^B$.

\begin{definition}\label{def:vcdim}
  The \emph{Vapnik-Chervonenkis (VC) dimension of $\range$} is the cardinality
  of the largest subset of $D$ that is shattered by $\range$.
\end{definition}

The main application of VC-dimension in statistics and learning
theory is in computing the number of samples needed to approximate the
probabilities associated to the ranges through their empirical averages.
Formally, let $X_1^k=(X_1,\dotsc,X_k)$ be a collection of independent
identically distributed random variables taking values in $D$, sampled 
according to some distribution $\phi$ on the elements of $D$.
For a set $A\subseteq D$, let $\phi(A)$ be the probability that a sample from
$\phi$ belongs to the set $A$, and let
\[
\phi_{X_1^k}(A)=\frac{1}{k}\sum_{j=1}^k\mathds{1}_A(X_j)\enspace.%, 
\]
%where $\mathds{1}_A$ is the indicator function for the set $A$. 
The function
$\phi_{X_1^k}(A)$ is the \emph{empirical average} of $\phi(A)$ on $X_1^k$.

\begin{definition}\label{def:eapprox}
  Let $\range$ be a range set on %a domain
  $D$ and $\phi$ be a probability distribution on $D$. For $\varepsilon\in(0,1)$,
  an \emph{$\varepsilon$-approximation to $(\range,\phi)$} is a bag $S$ of
  elements of $D$ such that 
  \[
  \sup_{A\in\range}|\phi(A)-\phi_S(A)|\le\varepsilon\enspace.\]
\end{definition}

An $\varepsilon$-approximation can be constructed by sampling points of
the domain according to the distribution $\phi$, provided an upper bound to the
VC-dimension of $\range$ or to its empirical VC-dimension is known:

\begin{theorem}[Thm.~2.12~\citep{HarPS11}]\label{thm:eapprox}
  (see also~\citep{LiLS01}). Let $\range$ be a range set on a domain $D$ with
  $\VC(\range)\le d$, and let $\phi$ be a distribution on $D$. Given
  $\varepsilon,\delta\in(0,1)$ let $S$ be a collection of $|S|$ points from $D$
  sampled according to $\phi$ for
  \begin{equation}\label{eq:vceapprox}
	|S|=\frac{c}{\varepsilon^2}\left(d+\ln\frac{1}{\delta}\right)
  \end{equation}
  where $c$ is an universal positive constant. Then, $S$ is an
  $\varepsilon$-approximation to $(\range,\phi)$ with probability at least
  $1-\delta$.
\end{theorem}
\citet{LofflerP09} showed experimentally that the constant $c$ is approximately
$0.5$. We used this value in our experiments.

