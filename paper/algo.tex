\section{Algorithms}\label{sec:algo}
In this section we present our algorithms to compute a set of approximations for the
betweenness centrality of the (top-$K$) vertices in a graph through sampling,
with probabilistic guarantees on the quality of the approximations.

\subsection{Approximation for all the vertices}\label{sec:allvertapprox}
The intuition behind the algorithm to approximate the betweenness values of all
vertices is the following. Given a graph $G=(V,E)$
with vertex-diameter $\VD(G)$ and two parameters $\varepsilon,\delta\in(0,1)$
we first compute a sample size $r$ using~\eqref{eq:vceapprox} with
$d=\lfloor\log_2(\VD(G)-2)\rfloor+1$:
\begin{equation}\label{eq:samplesize}
r=\frac{c}{\varepsilon^2}\left(\lfloor\log_2(\VD(G)-2)\rfloor+1+\ln\frac{1}{\delta}\right)\enspace.
\end{equation}
The sample size is sufficient to achieve the desired accuracy
(expressed through $\varepsilon$) with the desired confidence (expressed through
$1-\delta$). Then the algorithm repeats, for $r$ times, the following steps:
1.~it samples a pair $u,v$ of distinct vertices uniformly at random, 2.~it
computes the set $\mathcal{S}_{uv}$ of all shortest paths between $u$ and $v$,
3.~it selects a path $p$ from $\mathcal{S}_{uv}$ uniformly at random, 4.~ it
increases by $1/r$ the betweenness estimation of each vertex in
$\mathsf{Int}(p)$. Note that if the sampled vertices $u$ and $v$ are not
connected, we defined $\mathcal{S}_{uv}=\{p_\emptyset\}$ so nothing is done in
steps 3 and 4. Denoting with $S$ the set of the sampled shortest paths, the
unbiased estimator $\tilde\betw(w)$ for the betweenness $\betw(w)$ of a vertex
$w$ is the sample average 
\[
\tilde\betw(w) = \frac{1}{r}\sum_{p\in S}
\mathds{1}_{\mathsf{Int}(p)}(w) = \frac{1}{r}\sum_{p\in S}
\mathds{1}_{\mathcal{T}_w}(p)\enspace.
\]

There are two crucial steps in this algorithm: the computation of $\VD(G)$ and
the sampling of a path uniformly at random from $\mathcal{S}_{uv}$. We first
deal with the latter, and then present an approximation algorithm for $\VD(G)$.
%in Sect.~\ref{sec:diam}. 
Algorithm~\ref{alg:algorithm} presents the pseudocode of the algorithm,
including the steps to select a random path.  The
\texttt{computeAllShortestPaths(}$u,v$\texttt{)}  on
line~\ref{algline:shortestpaths} is a call to a modified Dijkstra's (or BFS)
algorithm to compute the set $\mathcal{S}_{uv}$, with the same modifications
as~\citet{Brandes01}. The \texttt{getDiameterApprox()} procedure is an
approximation algorithm for computing an approximation for $\VD(G)$. % (see Sect.~\ref{sec:diam} for details).

\paragraph{Unique shortest paths} When there is an unique (or no) shortest
path between each pair of vertices of $G$, then one can apply
Lemma~\ref{lem:vcdimuppboundunique} and obtain a smaller sample size
\[
  r= \frac{c}{\varepsilon^2}\left(3+\ln\frac{1}{\delta}\right)
\]
to approximate the betweenness values of all the vertices. 
This is an interesting result: the number of samples needed to compute a good
approximation to all vertices is a \emph{constant} and completely
\emph{independent from $G$}. Intuitively, this means that our algorithm will be
extremely efficient and scalable on graphs with this property. Unique shortest
paths are common or even enforced in road networks by slightly perturbing the
edge weights or having a deterministic tie breaking
policy~\citep{GeisbergerSS08}.

\paragraph{Bounded-distance betweenness} For the case of
$k$-bounded-distance betweenness, the sample size on line~\ref{algline:forloop}
of Alg.~\ref{alg:algorithm} can be reduced to 
\[ 
  r= \frac{c}{\varepsilon^2}\left(\lfloor\log_2(k-1)\rfloor + 1 +\ln\frac{1}{\delta}\right)
\]
and the computation of the shortest paths on line~\ref{algline:shortestpaths}
can be stopped after we reached the vertices that are $k$ ``hops'' far from $u$

%\paragraph{$k$-path betweenness}
%For the case of $k$-path betweenness, the algorithm is slightly different:
%for 
%\[
%  r= \frac{c}{\varepsilon^2}\left(\lfloor\log_2(k-1)\rfloor + 1 +\ln\frac{1}{\delta}\right)
%\]
%iterations, rather than sampling a pair of vertices $(uv)$, computing
%$\mathcal{S}_{uv}$, and then sampling a shortest path between them, we first sample a
%single vertex and an integer $\ell$ uniformly at random from $[1,k+1]$. We then
%perform a random walk touching $\ell$ vertices, while updating the estimated
%betweenness of each touched vertex by adding $1/r$ to its estimation.

\paragraph{Sampling a shortest path}
Our procedure to select a random shortest path from $\mathcal{S}_{uv}$ is
inspired by the dependencies accumulation procedure used in Brandes' exact
algorithm~\citep{Brandes01}. 
%Given a vertex $w$, ~\citet{Brandes01} showed how
%to compute, for every vertex $z$, the amount $\sigma_{wz}$ of shortest paths
%from $w$ to $z$, while computing the set $\mathcal{S}_{wz}$. 
Let $u$ and $v$ be the vertices sampled by our algorithm. We assume that $u$ and
$v$ are connected otherwise the only possibility is to select the empty path
$p_\emptyset$. Let $y$ be any vertex belonging to at least one shortest path
from $u$ to $v$. Following~\citet{Brandes01}, we can compute $\sigma_{uy}$ and
$\mathcal{S}_{uy}$ while we compute the set $\mathcal{S}_{uv}$ of all the
shortest paths from $u$ to $v$. We can then use this information to select a
shortest path $p$ uniformly at random from $\mathcal{S}_{uv}$. For each vertex
$w$ let $P_u(w)$ be the subset of neighbors of $w$ that are \emph{predecessors}
of $w$ along the shortest paths from $u$ to $w$. Let $p^*=\{v\}$. Starting from
$v$, we select one of its predecessors $z\in P_u(v)$ using weighted random
sampling: each $z\in P_u(v)$ has probability $\sigma_{uz}/\sum_{w\in
P_u(v)}\sigma_{uw}$ of being sampled. We add $z$ to $p^*$ and  then repeat the
procedure for $z$, selecting one of its predecessors from $P_u(z)$ and adding it
to $p^*$, and so on until we reach $u$. Note that we can update the estimation
of the betweenness of the internal vertices that are added to $p^*$ (the only
ones for which the estimation is updated) as we compute $p^*$.

\begin{lemma}\label{lem:samplpath}
  The path $p^*$ built according to the above procedure is selected uniformly at
  random among the paths in $\mathcal{S}_{uv}$.
\end{lemma}

\begin{proof}
%\begin{IEEEproof}
  The probability of sampling $p^*=(u,z_1,\dotsc,z_{|p^*|-2},v)$ equals to the
  product of the probabilities of sampling the vertices internal to $p^*$, hence
  \[
  \Pr(p^*)=\frac{\sigma_{uz_{|p^*|-2}}}{\sigma_{uv}}\frac{\sigma_{uz_{|p^*|-3}}}{\sigma_{uz_{|p^*|-2}}}\dotsb
  \frac{1}{\sigma_{uz_2}}=\frac{1}{\sigma_{uv}}
  \]
  where we used \citep[Lemma3]{Brandes01} which tells us that for $w\neq u$,
  \[
  \sigma_{uw}=\sum_{j\in P_u(w)}\sigma_{uj}
  \]
  and the fact that for $z_1$, which is a neighbor of $u$, $\sigma_{uz_1}=1$.
%\end{IEEEproof}
\end{proof}

\begin{algorithm}[ht]
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwComment{Comment}{//}{}
  \SetKwFunction{VertexDiameter}{getVertexDiameter}
  \SetKwFunction{SamplePair}{sampleUniformVertexPair}
  \SetKwFunction{SampleUniform}{sampleUniformPath}
  \SetKwFunction{PairShortestPaths}{computeAllShortestPaths}
   \DontPrintSemicolon
  %\dontprintsemicolon
  \Input{a graph $G=(V,E)$ with $|V|=n$, real values $\varepsilon,\delta\in(0,1)$}
  \Output{A set of approximations of the betweenness centrality of the vertices
  in $V$}
  \ForEach{$w\in V$}
  {
  $\tilde\betw(v)\leftarrow 0$
  }
  $\VD(G)\leftarrow$\VertexDiameter{G}\label{alg:diamcomp}\; 
  $r\leftarrow (c/\varepsilon^2)(\lfloor\log_2(\VD(G)-2)\rfloor+\ln(1/\delta))$\;
  \For{$i\leftarrow 1$ to $r$}
  {\label{algline:forloop}
  $(u,v)\leftarrow$\SamplePair{$V$}\;
  $\mathcal{S}_{uv}\leftarrow$\PairShortestPaths{$u,v$}\label{algline:shortestpaths}\;
  \If{$\mathcal{S}_{uv}\neq\{p_\emptyset\}$}
  {
  \Comment{Random path sampling and estimation update}
  $j\leftarrow v$\;
  $s\leftarrow v$\;
  $t\leftarrow v$\;
  \While{$t \neq u$} {
  sample $z\in P_s(t)$ with probability $\sigma_{uz}/\sigma_{us}$\;
  \If{$z\neq u$} {
  $\tilde\betw(z) \leftarrow \tilde\betw(z)+1/r$\;
  $s\leftarrow t$\;
  $t\leftarrow z$\;
  }
  }
  }
  } % end For
  \Return{$\{(v,\tilde\betw(v)), v\in V\}$}
  \caption{Computes approximations $\tilde\betw(v)$ of the betweenness
  centrality $\betw(v)$ for all vertices $v\in V$.}
  \label{alg:algorithm}
\end{algorithm}

\paragraph{Approximating the vertex-diameter}%\label{sec:diam}
The algorithm presented in the previous section requires the value of the
vertex-diameter $\VD(G)$ of the graph $G$ (line
\ref{alg:diamcomp} of Alg.~\ref{alg:algorithm}). 
Computing the exact value of $\VD(G)$ could be done by solving the All Pair
Shortest Paths (APSP) problem, and taking the shortest path with the maximum size.
Algorithms for exactly solving APSP problem such as Johnson's which runs in
$O(V^2\log V+VE)$ or Floyd-Warshall's ($\Theta(V^3)$), would defeat our
purposes: once we have all the shortest paths for the computation of
the diameter, we can also compute the betweenness of all the vertices exactly. 
Given that Thm.~\ref{thm:eapprox} (and Thm.~\ref{thm:releapprox} too) only
requires an upper bound to the VC-dimension of the range set, an approximation
of the vertex-diameter would be sufficient for our purposes. Several refined
algorithms for approximating the diameter are
known~\citep{AingwordCIM99,BoitmanisFL06,RodittyW12}, with various running times
and quality of approximations. We briefly present a well-known and simple
approximation algorithm that has the right balance of accuracy and speed
for our purposes.

Let $G=(V,E)$ be an \emph{undirected} graph where \emph{all the edge weights are
equal}.
It is a folklore result that one can obtain a $2$-approximation
$\widetilde\VD(G)$ of the vertex-diameter $\VD(G)$ of $G$ in time $O(V+E)$ in
the following way: 1.~select a vertex $v\in V$ uniformly at random, 2.~compute
the shortest paths from $v$ to all other vertices in $V$, and 3.~finally take
$\widetilde\VD(G)$ to be the sum of the lengths of the two shortest paths with
maximum size (which equals to the two longest shortest paths) from $v$ to two
distinct other nodes $u$ and $w$. 
\ifproof
The approximation guarantee follows from the next lemma.

\begin{lemma}\label{lem:diam}
  $\VD(G)\le\widetilde\VD(G)\le 2\VD(G)$.
\end{lemma}
\begin{proof}
%\begin{IEEEproof}
  Let $v\in V$ be a vertex that we choose uniformly at random from the set $V$.
  Let also $u,w\in V$ be the two vertices such that the sum of the sizes of the
  shortest paths $p_{vu}$ and $p_{vw}$ is maximized among all the shortest paths
  that have $v$ as a source.  We have $\widetilde\VD(G)\le 2\VD(G)$ because
  $|p_{vu}|,|p_{vw}|\le\VD(G)$, so $|p_{vu}|+|p_{vw}|\le 2\VD(G)$. To see
  that $\widetilde\VD(G)\ge\VD(G)$, consider a pair of vertices $x$ and $z$ such
  that the length of a shortest path between $x$ and $z$ is equal to $\VD(G)$.
  Let $p_{xv}$ be a shortest path between $x$ and $v$ and let $p_{vz}$ be a
  shortest path between $v$ and $z$. 
  From the properties of the shortest paths $p_{vu}$, $p_{vw}$ we have
  $|p_{vu}|+|p_{vw}|\geq |p_{vx}|+|p_{vz}|$. Since the graph is undirected
  $|p_{s,t}|=|p_{t,s}|$ for every $s,t\in V$.
  Therefore:
  \[
    \widetilde\VD(G) = |p_{vu}|+|p_{vw}|\geq |p_{vx}|+|p_{vz}| =
    |p_{xv}|+|p_{vz}|\ge\VD(G)\enspace. 
  \]
  For the last inequality we used the fact that since $\VD(G)$ is the size of
  the shortest path from $x$ to $z$, then every other path (in this case
  $p'_{xz}$ which is the merge of $p_{xv}$ and $p_{vz}$) has greater or equal
  length from $p_{x,z}$.
  %$\qed$
%\end{IEEEproof}
\end{proof}
\fi
In case we have multiple connected components in $G$, we compute an upper bound
to the vertex diameter of each component separately by running the above
algorithm on each component, and then taking the maximum. 
The connected components can be computed in $O(n+m)$ by traversing the graph in
a Breadth-First-Search (BFS) fashion starting from a random $v$.
%Let $\tilde\Delta_{G_{1}},\tilde\Delta_{G_{2}}, \ldots , \tilde\Delta_{G_{k}}$
%be the approximations of the diameter for each of the $k$ connected components
%of $G$ as if they were separate graphs.
%The output of the approximation for the graph $G$, is the maximum of the values
%$\tilde\Delta_{G_{1}},\tilde\Delta_{G_{2}}, \ldots , \tilde\Delta_{G_{k}}$.
The time complexity of the approximation algorithm in the case of multiple
connected components is again $O(n+m)$ since the sum of the vertices of
individual components is $n$ and the sum of edges is $m$. 

The use of the above $2$-approximation in the computation of the
sample size from line~\ref{algline:forloop} of Alg.~\ref{alg:algorithm} results
in at most $c/\varepsilon^2$ additional samples than if we
used the exact value $\VD(G)$. Furthermore, the computation of $\widetilde\VD(G)$
does not affect the running time of our algorithm since for the construction of
the first sample we can reuse the already computed shortest paths from the
vertex $v$ used to obtain the approximation. Specifically, we can sample a new
vertex $u\neq v$ and then choose with uniform probability one of the
(already computed) shortest paths between $v$ and $u$.

If the graph is directed and/or not all edge weights are equal, the computation of a good
approximation to $\VD(G)$ becomes more problematic. In particular, notice that
there is no relationship between $\VD(G)$ and $\mathsf{diam}(G)$ when $G$ is
weighted, as the shortest path with maximum size may not be the shortest path
with maximum weight. In these cases, one can use the size (number of vertices)
of the largest Weakly Connected Component (WCC) , as upper bound to $\VD(G)$.
The WCC's can again be computed in $O(n+m)$ using BFS. Although this quantity
can be as high as $n$, in the computation of the sample size we use its
logarithm. This has the effect of making our sample size comparable with that
proposed by~\citet{BrandesP07} when there is a single WCC, as it would depend on
$\log n$, but the amount of work done per sample in our algorithm is still much
smaller, in practice, than that performed by the algorithm they presented (see
Sect.~\ref{sec:discussion} and~\ref{sec:exper} for more details). We believe
that in practical situation, a much better upper bound to the diameter of the
graph is available, resulting in a smaller sample size than what suggested by
the worst case we just presented


\paragraph{Analysis}\label{sec:analysis}
The algorithm we described and presented in Algorithm~\ref{alg:algorithm} offers
probabilistic guarantees on the quality of all approximations of the betweenness
centrality.
\begin{lemma}\label{lem:correctness}
  With probability at least $1-\delta$, all the approximations computed by the
  algorithm are within $\varepsilon$ from their real value:
  \[
  \Pr\left(\exists v\in V \mbox{ s.t. }
  |\betw(v)-\tilde\betw(v)|>\varepsilon\right)<\delta\enspace .
  \]
\end{lemma}

\begin{proof}
%\begin{IEEEproof}
  For each $p_{uv}\in\mathbb{S}_G$ let
  \[
  \pi_G(p_{uv})=\frac{1}{n(n-1)}\frac{1}{\sigma_{uv}}\enspace.
  \]
  It is easy to see that $\pi_G$ is a probability distribution and
  $\pi_G(p_{uv})$ is the probability of sampling the path $p_{uv}$ during an
  execution of the loop on line~\ref{algline:forloop} in
  Alg.~\ref{alg:algorithm}, given the way that the vertices $u$ and $v$ are
  selected and Lemma~\ref{lem:samplpath}.
  
  Consider the range set $\range_G$ and the probability distribution $\prob_G$.
  Let $S$ be the set of paths sampled during the execution of the algorithm.
  For $r$ as in~\eqref{eq:samplesize}, Thm.~\ref{thm:eapprox} tells us that the sample $S$ is a
  $\varepsilon$-approximation to $(\range_G,\prob_G)$ with probability at least
  $1-\delta$. Suppose that this is indeed the case, then from
  Def.~\ref{def:eapprox} and the definition of $\range_G$ we have that
  \[
  \left|\prob_G(\mathcal{T}_v) - \frac{1}{r}\sum_{p\in
  S}\mathds{1}_{\mathcal{T}_v}(p)\right|=\left|\prob_G(\mathcal{T}_v) -
  \tilde\betw(v)\right|\le\varepsilon, \forall v\in
  V\enspace.
  \]
  From the definition of $\prob_G$ we have
  \[
  \prob_G(\mathcal{T}_v)=\frac{1}{n(n-1)}\sum_{p_{uw}\in\mathcal{T}_v}\frac{1}{\sigma_{uw}}=\betw(v),
  \]
  which concludes the proof.
%\end{IEEEproof}
\end{proof}

\subsection{High-quality approximation of the top-$K$ betweenness
vertices}\label{sec:topk}
%\XXX It would be great to look at the paper by Ezra, ``Small-Size Relative
%$(p,\varepsilon)$-Approximations for Well-Behaved Range Spaces'', 2012,
%available on the arXiv. She presents a smaller bound to the sample size for a
%relative $(p,\varepsilon$-approximation if the range set is ``well-behaved''. We
%should check whether ours is. (Warning: the paper is not exactly an example of
%clarity\ldots)

Very often in practice one is interested only in identifying the vertices with
the highest betweenness centrality, as they are the ``primary actors'' in the
network. We present here an algorithm to compute a very high-quality
approximation of the set $\TOPK(K,G)$ of the top-$K$ betweenness vertices in a graph
$G=(V,E)$. Formally, let $v_1,\dotsc,v_n$ be a labelling of the vertices in $V$
such that $\betw(v_i)\ge\betw(v_j)$ for $1\le i<j\le n$. Then $\TOPK(K,G)$ is
defined as the set of vertices with betweenness at least $\betw(v_K)$:
\[
\TOPK(K,G)=\{(v,\betw(v)), ~:~ v\in V \mbox{ and } \betw(v)\ge\betw(v_K)\}\enspace.
\]
Note that $\TOPK(K,G)$ may contain more than $K$ vertices. 
%This is in line with
%the definition of the set of top-$k$ Frequent Itemsets in the market basket
%analysis setting \XXX add reference.

Our algorithm works in two phases. Each phase is basically a run of the
algorithm for approximating the betweenness of all vertices presented in the
previous section, with some additional computation at the end of each phase and
different ways to compute the number of paths to sample. In the first phase,
we compute a lower bound $\ell'$ to $\betw(v_K)$. In the second phase we use
$\ell'$ to compute the number of samples needed to obtain a relative
$(\ell',\varepsilon)$-approximation to the $(\range_G,\pi_G)$. Then we use this
number of samples to approximate the betweenness of all vertices again, and
return a collection of vertices that is, with high probability, a superset of
$\TOPK(K,G)$.

Let $\widetilde\VD(G)$ be an upper bound to the vertex-diameter of $G$. Given
$\varepsilon,\delta\in(0,1)$, let $\delta',\delta''$ be two positive reals such
that $(1-\delta')(1-\delta'')\ge(1-\delta)$. Let
\[
r'=\frac{c}{\varepsilon^2}\left(\lfloor\log_2(\widetilde\VD(G)-2)\rfloor+1+\log\frac{1}{\delta'}\right)\enspace.
\]
Let $\tilde\betw'_k$ be the $K$-th highest estimated betweenness obtained using
Algorithm~\ref{alg:algorithm} where $r=r'$, and let
\[
  \ell'=\tilde\betw_K-\varepsilon.
\]
Let
\[
r''=\frac{c'}{\varepsilon^2\ell'}\left((\lfloor\log_2(\widetilde\VD(G)-2)\rfloor+1)\log\frac{1}{\ell'}+\log\frac{1}{\delta''}\right)\enspace.
\]
We run Algorithm~\ref{alg:algorithm} with $r=r''$ and let $\tilde\betw''_K$ be
the so-obtained $K$-th highest estimated betweenness. Let
$\ell''=\min\{\tilde\betw''(v) / (1+\varepsilon) ~:~ v\in V \mbox{ s.t. }
\tilde\betw''(v)\ge\tilde\betw''_K\}$. We
return the collection $\widetilde\TOPK(K,G)$ of vertices $v$ such that
$\tilde\betw''(v)*(1+\varepsilon)/(1-\varepsilon)\ge\ell''$:
\[
\widetilde\TOPK(K,G)= \left\{v\in V ~:~
\tilde\betw''(v)\frac{1+\varepsilon}{1-\varepsilon}\ge\ell''\right\}\enspace.
\]
\ifproof
The pseudocode of the algorithm is presented in Algorithm~\ref{alg:topk}.

\begin{algorithm}[ht]
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwComment{Comment}{//}{}
  \SetKwFunction{VertexDiameter}{getVertexDiameter}
  \SetKwFunction{SamplePair}{sampleUniformVertexPair}
  \SetKwFunction{SampleUniform}{sampleUniformPath}
  \SetKwFunction{PairShortestPaths}{computeAllShortestPaths}
   \DontPrintSemicolon
  %\dontprintsemicolon
  \Input{a graph $G=(V,E)$ with $|V|=n$, a positive integer $K\le n$, real
  values $\varepsilon,\delta\in(0,1)$}
  \Output{a superset of $\TOPK(K,G)$, with high-quality estimation of the
  betweenness for the vertices in the returned set.}
  $\delta',\delta''\leftarrow$ two positive reals such that
  $(1-\delta')(1-\delta'')\ge(1-\delta)$\;
  $\widetilde\VD(G)\leftarrow$ upper bound to $\VD(G)$\;
  \Comment{First phase}
  $r'\leftarrow\frac{c}{\varepsilon^2}\left(\lfloor\log_2(\widetilde\VD(G)-2)\rfloor+1+\log\frac{1}{\delta''}\right)$\;
  $B'=\{(v,\tilde\betw'(v)) ~:~ v\in V\}\leftarrow$ output of Algorithm~\ref{alg:algorithm} with $r=r'$\;
  $\tilde\betw_K'\leftarrow$ $K$-th highest betweenness value from $B'$, ties
  broken arbitrarily\;
  $\ell'\leftarrow\tilde\betw_K'-\varepsilon$\;
  $r''\leftarrow\frac{c'}{\varepsilon^2\ell'}\left((\lfloor\log_2(\widetilde\VD(G)-2)\rfloor+1)\log\frac{1}{\ell'}+\log\frac{1}{\delta''}\right)$\;
  \Comment{Second phase}
  $B''=\{(v,\tilde\betw''(v)) ~:~ v\in V\}\leftarrow$ output of
  Algorithm~\ref{alg:algorithm} with $r=r''$\;
  $\tilde\betw_K''\leftarrow$ $K$-th highest betweenness value from $B''$, ties
  broken arbitrarily\;
  $\ell''\leftarrow\min\{\tilde\betw''(v)/(1+\varepsilon) ~:~ v \mbox{ s.t. }
  \tilde\betw''(v)\ge\tilde\betw_K''\}$\;
  \Return $\{(v,\tilde\betw''(v)) ~:~ v\in V \mbox{ s.t. }
  \tilde\betw''(v)\frac{1+\varepsilon}{1-\varepsilon}\ge\ell''\}$\;
  \caption{High-quality approximation of the top-$K$ betweenness vertices}
  \label{alg:topk}
\end{algorithm}
\fi

\paragraph{Analysis}
The following lemma shows the properties of the collection $\widetilde\TOPK(K,G)$.
\begin{lemma}
  With probability at least $1-\delta$, 
  \begin{enumerate*}
    \item $\TOPK(K,G)\subseteq \widetilde\TOPK(K,G)$, and
    \item for all $v\in\TOPK(K,G)$ we have
      $|\tilde\betw''(v)-\betw(v)|\le\varepsilon\betw(v)$.
    \item no vertex $u\in\widetilde\TOPK(K,G)\setminus\TOPK(K,G)$ has an estimated
      betweenness greater than $\ell'(1+\varepsilon)$.
  \end{enumerate*}
\end{lemma}
\begin{proof}
%\begin{IEEEproof}
  We start by proving 1. From Thm.~\ref{thm:eapprox} we know that, with probability at least
  $1-\delta'$, a sample of size $r'$ is a $\varepsilon$-approximation to
  $(\range_G,\pi_G)$ and from Thm.~\ref{thm:releapprox} we have that with
  probability at least $1-\delta''$ a sample of size $r''$ is a relative
  $(\ell',\varepsilon)$-approximation to $(\range_G,\pi_G)$. Suppose both these
  events occur, which happens with probability at least $1-\delta$. Then it is
  easy to see that $\ell'\le\betw(v_K)$, as there must be at least $K$ vertices
  with exact betweenness greater or equal to $\ell'$.  Consider now $\ell''$.
  Following the same reasoning as for $\ell'$, it should be clear that
  $\ell''\le\betw(v_K)$. The vertices included in $\widetilde\TOPK(K,G)$ are all and
  only those vertices that \emph{may} have exact betweenness at least $\ell''$,
  which implies that all vertices that have exact betweenness at least
  $\betw(v_K)$ are included in $\widetilde\TOPK(K,G)$. 
  Points 2 and 3 in the thesis follow from the properties of the relative
  $(\ell',\varepsilon)$-approximation (Def.~\ref{def:releapprox}).
%\end{IEEEproof}
\end{proof}

The advantage of using our algorithm to approximate the collection of top-$K$
betweenness vertices consists in the very high-quality approximation of the
betweenness values for the returned set of vertices: they are all within a
multiplicative factor $\varepsilon$ from their exact values. By reverse-sorting
them according to the approximated betweenness, one can obtain a ranking that is
very similar to the original exact one.\XXX Experiments should show this
Previous algorithms did not offer such a good ranking as they were only able to
approximate the betweenness values to within an additive error $\varepsilon$.
The cost of computing the high quality approximation for the top-$K$ vertices is
the cost of an additional run of our algorithm to compute good approximations
for all the vertices.

\subsection{Discussion}\label{sec:discussion}
\citet{JacobKLPT05} and independently~\citet{BrandesP07} present an algorithm
that also uses sampling to approximate the betweenness centrality of all the
vertices of the graph. The algorithm creates a sample $S=\{v_1,\dotsc,v_r\}$ of
$r$ vertices drawn uniformly at random and computes all the shortest paths
between each $v_i$ to all other vertices in the graph. The estimation
$\tilde\betw'(u)$ for the betweenness centrality $\betw(u)$ is
\[ 
\tilde\betw'(u)= \frac{1}{(n-1)r}\sum_{v_i\in S}\sum_{w\neq v_i,w\neq
u}\sum_{p\in\mathcal{S}_{v_iw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{v_iw}|}\enspace.
\]
As it was for our algorithm, the key ingredient to ensure a correct
approximation for the betweenness centrality is the computation of the sample
size $r$. Inspired by the work of~\citet{EppsteinW04}, \citet{BrandesP07} rely
on the following classical result by~\citet{Hoeffding63} for their computation
of $r$.
%\begin{theorem}[\citep{Hoeffding63}]
%  Let $X_1,X_2,\dotsc,X_r$ be a sequence of independent random variables
%  such that $a_i\leq X_i\leq b_i$. Then for any $\xi > 0$
%  \begin{align}\label{eq:hoeffding}
%    \begin{split}
%      \Pr&\left(\left|\frac{|\sum_{i=1}^rX_i|}{r}-\mathbf{E}\left[\frac{|\sum_{i=1}^rX_i|}{r}\right]\right|\geq
%    \xi\right)\le \\
%      &\leq 2e^{-2r^2\xi^2/\sum_{i=1}^{r}(b_{i}-a_{i})^2}\enspace.
%    \end{split}
%  \end{align}
%\end{theorem}
%
%\citet{BrandesP07} use this result to compute a sample size $r$ sufficient to ensure that, for
%a fixed vertex $u$,
%\[ 
%\Pr\left(|\betw(u)-\tilde\betw'(u)|>\varepsilon\right)<\frac{\delta}{n}\enspace.
%\]
%In their setting $\xi=\varepsilon$ and there is a variable $X_i$ for
%each vertex $v_i$ in the sample:
%\[ 
%X_i=\frac{1}{n-1}\sum_{w\neq v_i,w\neq
%u}\sum_{p\in\mathcal{S}_{v_iw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{v_iw}|}\enspace
%.
%\]
%It is easy to see that $0\le X_i\le 1$. Moreover,
%\[
%  \mathbf{E}\left[\frac{|\sum_{i=1}^r X_i}{r}\right] = \betw(u)\enspace.
%\]
%%\begin{align*}
%%\mathbf{E}\left[\frac{|X_1+\dotsb+X_r|}{r}\right] &=
%%\frac{1}{r(n-1)}\mathbf{E}\left[\sum_{v_i\in S}\sum_{w\neq v_i,w\neq
%%u}\sum_{p\in\mathcal{S}_{v_iw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{v_iw}|}\right]
%%=\frac{1}{r(n-1)}\sum_{v\in V}\mathbf{E}\left[Y_v\sum_{w\neq v,w\neq
%%u}\sum_{p\in\mathcal{S}_{vw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{vw}|}\right] =
%%\\
%%&=\frac{1}{r(n-1)}\sum_{v\in V}\mathbf{E}[Y_v]\sum_{w\neq v,w\neq
%%u}\sum_{p\in\mathcal{S}_{vw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{vw}|}
%%=\frac{1}{r(n-1)}\sum_{v\in V}\frac{r}{n}\sum_{w\neq v,w\neq
%%u}\sum_{p\in\mathcal{S}_{vw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{vw}|}
%%= \betw(u),
%%\end{align*}
%%where $Y_v$ is a Bernoulli random variable taking value 1 if $v\in S$, and 0
%%otherwise, so $\mathbf{E}[Y_v]=\Pr(Y_v=1)=r/n$.
%Plugging these values in~\eqref{eq:hoeffding}, we have
%\[
%\Pr\left(|\betw(u)-\tilde\betw'(u)|>\varepsilon\right)\leq
%2e^{-2r\epsilon^2}\enspace.
%\]
%We want this probability to be at most $\delta/n$, so we need a sample of size
They prove that, to obtain good (within $\pm\varepsilon$) estimations for the
betweenness of all vertices with probability at least $1-\delta$, it must be
\[
r\geq \frac{1}{2\varepsilon^2}\left(\ln n + \ln 2 +\ln\frac{1}{\delta}\right)\enspace.
\]
%An application of the union bound over the $n$ vertices ensures a uniform
%(simultaneous) guarantee on the quality of
%all the estimation, with probability at least $1-\delta$.
From this expression it should be clear that this sample size is usually much
larger than ours, as in practice $\VD(G)\ll n$. For the same reason, the
algorithm would not scale well with the size of the network, as we also evaluate
experimentally (see Sect.~\ref{sec:exper}).

Another interesting aspect in which our algorithm and the one
by~\citet{JacobKLPT05} and~\citet{BrandesP07} differ is the \emph{amount of work
done per sample}. Our algorithm computes a single set $\mathcal{S}_{uv}$ for the
sampled vertices $u$ and $v$ by performing a run of Dijkstra's algorithm or of
BFS until $v$ is reached or all the vertices reachable from $u$ have been
explored. The algorithm from~\citep{JacobKLPT05,BrandesP07} instead computes
all the sets $\mathcal{S}_{uw}$ from the sampled vertices $u$ to all other
vertices, again with a single run of Dijkstra or BFS, but without the
``early-stopping condition'' that we have when we reach $v$. Although in the
worst case the two computations have the same time complexity\footnote{It is a
well-known open problem whether there is an algorithm to perform a single
$s,t$-shortest path computation between a pair of vertices with smaller
worst-case time complexity than the Single Source Shortest Path computation.}, in practice we
perform much fewer operations, as we can expect $v$ not to always be very
far from $u$ and therefore we can terminate early. This fact has a great
impact on the running time, especially because our algorithm touches
\emph{much fewer} edges than the algorithm from~\citep{JacobKLPT05,BrandesP07},
given that this one can actually touch the entire network, i.e., all the edges
in the graph, at every sample, while our computation has a much higher
\emph{locality}, exploring only a neighborhood of $u$ until $v$ is reached. The
results of our experimental evaluation presented in Sect.~\ref{sec:exper}
highlights this and other advantages of our method over the one
from~\citep{JacobKLPT05,BrandesP07}. In the future, we plan to investigate the
possibility of using \emph{bidirectional A$^*$
search}~\citep{Pohl69,KaindlK97} to further speed up the computation for each
sample of our algorithms.

