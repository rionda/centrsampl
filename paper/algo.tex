\section{Algorithm}\label{sec:algo}
In this section we present our algorithm to compute a set of approximations for the
betweenness centrality of all vertices in a graph through sampling, with
probabilistic guarantees on the quality of the approximations.

The intuition behind the algorithm is the following. Given a graph $G=(V,E)$
with vertex-diameter $\Delta_G$ and two parameters $\varepsilon,\delta\in(0,1)$
we first compute a sample size $r$ using~\eqref{eq:vceapprox} with
$d=\lfloor\log_2(\Delta_G-2)\rfloor+1$:
\begin{equation}\label{eq:samplesize}
r=\frac{c}{\varepsilon^2}\left(\lfloor\log_2(\Delta_G-2)\rfloor+1+\ln\frac{1}{\delta}\right)\enspace.
\end{equation}
The sample size is sufficient to ensure to achieve the desired accuracy
(expressed through $\varepsilon$) with the desired confidence (expressed through
$1-\delta$). Then the algorithm repeats, for $r$ times, the following steps:
1.~it samples a pair $u,v$ of distinct vertices uniformly at random, 2.~it
computes the set $\mathcal{S}_{uv}$ of all shortest paths between $u$ and $v$,
3.~it selects a path $p$ from $\mathcal{S}_{uv}$ uniformly at random and
increase by $n(n-1)$ the betweenness estimation of each vertex in
$\mathsf{Int}(p)$. Note that if the sampled vertices $u$ and $v$ are not
connected, we defined $\mathcal{S}_{uv}=\{p_\emptyset\}$ so nothing is done in
step 3. In the end, the estimator for the betweenness $\betw(w)$ of a vertex $w$
is 
\[
\tilde\betw(w) = \frac{n(n-1)}{k}\sum_{p\in S}
\mathds{1}_{\mathsf{Int}(p)}(w) = \frac{n(n-1)}{k}\sum_{p\in S}
\mathds{1}_{\mathcal{T}_w}(p)\enspace.
\]

There are two crucial steps in this algorithm: the computation of $\Delta_G$ and
the sampling of a path uniformly at random from $\mathcal{S}_{uv}$. We first
deal with the latter, and then present an approximation algorithm for $\Delta_G$
in Sect.~\ref{sec:diam}. Algorithm~\ref{alg:algorithm} presents the
pseudocode of the algorithm, including the steps to select a random path.
The \texttt{getDiameterApprox()} procedure is our approximation algorithm for
computing an approximation for $\Delta_G$ and its pseudocode is presented in
Alg.~\ref{alg:diam}.

\paragraph{Sampling a shortest path}
Our procedure to select a random shortest path from $\mathcal{S}_{uv}$ is
inspired by the dependencies accumulation procedure used in Brandes' exact
algorithm~\citep{Brandes01}. Given a vertex $w$, ~\citet{Brandes01} showed how
to compute, for every vertex $z$, the number $\sigma_{wz}$ of shortest paths
from $w$ to $z$. We can compute this number for every vertex belonging to at
least one path from the sampled vertex $u$ to the sampled vertex $v$ while we
compute the set $\mathcal{S}_{uv}$ of all the shortest paths from $u$ to $v$. We
can use this information to select a shortest path $p$ uniformly at random from
$\mathcal{S}_{uv}$. We assume that $u$ and $v$ are connected, otherwise, the
only possibility is to select the empty path $p_\emptyset$. For each vertex $w$
let $P_u(w)$ be the subset of neighbors of $w$ that are \emph{predecessors} of
$w$ along the shortest paths from $u$ to $w$. Let $p^*=\{v\}$. Starting from $v$,
we select one of its predecessors $z\in P_u(v)$ using a weighted random sampling
where each $z\in P_u(v)$ has probability $\sigma_{uz}/\sum_{w\in
P_u(v)}\sigma_{uz}$ of being sampled. We add $z$ to $p^*$ and  then repeat the
procedure for $z$, selecting one of its predecessors from $P_u(z)$ and adding it
to $p^*$, and so on until we reached $u$. Note that we can update the estimation
of the betweenness of the internal vertices that are added to $p^*$ (the only
ones for which the estimation is updated) as we compute $p^*$.

\begin{lemma}
  The path $p*$ built according to the above procedure is selected uniformly at
  random among the paths in $\mathcal{S}_{uv}$.
\end{lemma}
\begin{proof}
  The probability of sampling $p^*=(u,z_1,\dotsc,z_{|p^*|-2},v)$ equals to the
  product of the probabilities of sampling the vertices internal to $p^*$, hence
  \[
  \Pr(p^*)=\frac{\sigma_{uz_{|p^*|-2}}}{\sigma_{uv}}\frac{\sigma_{uz_{|p^*|-3}}}{\sigma_{uz_{|p^*|-2}}}\dotsb
  \frac{1}{\sigma_{uz_2}}=\frac{1}{\sigma_{uv}}
  \]
  where we used \citep[Lemma3]{Brandes01} which tells us that for $w\neq u$,
  \[
  \sigma_{uw}=\sum_{j\in P_u(w)}\sigma_{uj}
  \]
  and the fact that for $z_1$, which is a neighbor of $u$, $\sigma_{uz_1}=1$.
\end{proof}

\begin{algorithm}[h]
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwComment{Comment}{//}{}
  \SetKwFunction{VertexDiameter}{getVertexDiameter}
  \SetKwFunction{SamplePair}{sampleUniformVertexPair}
  \SetKwFunction{SampleUniform}{sampleUniformPath}
  \SetKwFunction{PairShortestPaths}{computeAllShortestPaths}
   \DontPrintSemicolon
  %\dontprintsemicolon
  \Input{a graph $G=(V,E)$ with $|V|=n$, real values $\varepsilon,\delta\in(0,1)$}
  \Output{A set of approximations of the betweenness centrality of the vertices
  in $V$}
  \ForEach{$w\in V$}
  {
  $\tilde\betw(v)\leftarrow 0$
  }
  $\Delta_G\leftarrow$\VertexDiameter{G}\label{alg:diamcomp}\; 
  $r\leftarrow (c/\varepsilon^2)(\lfloor\log_2(\Delta_G-2)\rfloor+\ln(1/\delta))$\;
  \For{$i\leftarrow 1$ to $r$}
  {\label{algline:forloop}
  $(u,v)\leftarrow$\SamplePair{$V$}\;
  $\mathcal{S}_{uv}\leftarrow$\PairShortestPaths{$u,v$}\;
  \Comment{Random path sampling and estimation update}
  \If{$\mathcal{S}_{uv}\neq\{p_\emptyset\}$}
  {
  $j\leftarrow v$\;
  $s\leftarrow v$\;
  $t\leftarrow v$\;
  \While{$t \neq u$} {
  sample $z\in P_u(t)$ with probability $\sigma_{uz}/\sigma_{us}$\;
  \If{$z\neq u$} {
  $\tilde\betw(z) \leftarrow \tilde\betw(z)+\binom{|V|}{2}$\;
  $s\leftarrow t$\;
  $t\leftarrow z$\;
  }
  }
  }
  } % end For
  \Return{$\{\tilde\betw(v), v\in V\}$}
  \caption{Computes approximations $\tilde\betw(v)$ of the betweenness
  centrality $\betw(v)$ for all vertices $v\in V$.}
  \label{alg:algorithm}
\end{algorithm}

The algorithm we described offers probabilistic guarantees on the quality of all
approximations of the betweenness centrality.
\begin{lemma}\label{lem:correctness}
  With probability at least $1-\delta$, all the approximations computed by the
  algorithm are within $\varepsilon\binom{n}{2}$ from their real value:
  \[
  \Pr\left(\exists v\in V \mbox{ s.t. }
  |\betw(v)-\tilde\betw(v)|>\varepsilon\binom{n}{2}\right)<\delta\enspace .
  \]
\end{lemma}

\begin{proof}
  For each $p_{uv}\in\mathbb{S}_G$ let
  \[
  \pi_G(p_{uv})=\frac{1}{n(n-1)|\mathcal{S}_{uv}|}\enspace.
  \]
  It is easy to see that $\pi_G$ is a probability distribution and
  $\pi_G(p_{uv})$ is the probability of sampling the path $p_{uv}$ during an
  execution of the loop on line~\ref{algline:forloop} in
  Alg.~\ref{alg:algorithm}.
  
  Consider the range set $\range_G$ and the probability distribution $\prob_G$.
  Let $S$ be the set of paths sampled during the execution of the algorithm.
  For $r$ as in~\eqref{eq:samplesize}, Thm.~\ref{thm:eapprox} tells us that the sample $S$ is a
  $\varepsilon$-approximation to $(\range_G,\prob_G)$ with probability at least
  $1-\delta$. Suppose that this is indeed the case, then from
  Def.~\ref{def:eapprox} and the definition of $\range_G$ we have that
  \[
  \left|\prob_G(\mathcal{T}_v) - \frac{1}{k}\sum_{p\in
  S}\mathds{1}_{\mathcal{T}_v}(p)\right|=\left|\prob_G(\mathcal{T}_v) -
  \frac{1}{n(n-1)}\tilde\betw(v)\right|\le\varepsilon, \forall v\in
  V\enspace.
  \]
  From the definition of $\prob_G$ we have
  \[
  \prob_G(\mathcal{T}_v)=\frac{1}{n(n-1)}\sum_{p_{uw}\in\mathcal{T}_v}\frac{1}{|\mathcal{S}_{uw}|}=\frac{1}{n(n-1)}\betw(v),
  \]
  which concludes the proof.
\end{proof}

\paragraph{Unique shortest paths case} When the graph $G$ is undirected and
there is an unique shortest path between each pair of node, then one can apply
Lemma~\ref{lem:vcdimuppboundunique} and obtain a smaller sample size
\[ k= \frac{c}{\varepsilon^2}\left(3+\ln\frac{1}{\delta}\right)
\]
to approximate the betweenness centralities of all the vertices. Unique shortest
paths are common in or even enforced in road networks~\citep{GeisbergerSS08} by
slightly perturbing the edge weights or having a deterministic tie breaking
policy.

\subsection{Approximating the diameter}\label{sec:diam}
The algorithm presented in the previous section requires the value of the vertex-diameter $\Delta_G$ of the graph $G$ (line
\ref{alg:diamcomp} of Alg.~\ref{alg:algorithm}). 
Computing the exact value of $\Delta_G$ can be done by solving the all pair shorter paths (APSP) problem, and taking the
shortest path with the maximum size.
Algorithms for exactly solving APSP problem such as Johnson's which runs in $O(V^2logV+VE)$, Floyd-Warshall's runs in $\Theta(V^3)$, would defeat our purposes.
The reason is that once we have all the shortest paths for the computation of the diameter, we can also compute the betweenness of all the nodes exactly. 
Given that Thm.~\ref{thm:eapprox} only requires an upper bound to the VC-dimension of the range set, an approximation of the vertex-diameter would be sufficient for our purposes.
The computation of the approximation not only affects the time complexity of our algorithm but also the number of samples that we need.
Several refined algorithms for approximating the diameter are known~\citep{AingwordCIM99,BoitmanisFL06,RodittyW12}, with various running times and quality of approximations.
 We briefly present a well-known and simple approximation algorithm that has the right balance of accuracy and speed for our purposes.


Let $G=(V,E)$ be an \emph{undirected} where \emph{all the weights are unitary}.
We can form a $2$-approximation algorithm for the diameter $\Delta_G$ of $G$ in time $O(V+E)$ in the following way, 
select a vertex $v\in V$ uniformly at random, compute the shortest paths from $v$ to all other vertices in $V$, and finally take
$\tilde\Delta_G$ to be the sum of the lengths of the two longest shortest paths
from $v$ to two distinct other nodes $u$ and $w$.
The approximation guarantee follows from the next lemma.


\begin{lemma}\label{lem:diam}
  $\Delta_G\le\tilde\Delta_G\le 2\Delta_G$.
\end{lemma}
\begin{proof}
  Let $v\in V$ be a vertex that we choose uniformly at random from the set $V$.
  Let also $u,w\in V$ be the two vertices such that the sum of the shortest paths $p_{vu}$ and $p_{vw}$ is maximized among all the shortest paths that have $v$ as a source.
  We have $\tilde\Delta_G\le 2\Delta_G$ because
  $|p_{vu}|,|p_{vw}|\le\Delta_G$, so $|p_{vu}|+|p_{vw}|\le 2\Delta_G$. To see
  that $\tilde\Delta_G\ge\Delta_G$, consider a pair of nodes $x$ and $z$ such
  that the length of a shortest path between $x$ and $z$ is equal to $\Delta_G$.
  Let $p_{xv}$ be a shortest path between $x$ and $v$ and let $p_{vz}$ be a
  shortest path between $v$ and $z$. 
  From the properties of the shortest paths $p_{vu}$, $p_{vw}$ we have $|p_{vu}|+|p_{vw}|\geq |p_{vx}|+|p_{vz}|$
  Since the graph is undirected $|p_{s,t}|=|p_{t,s}|$ for every $s,t\in V$.
  Therefore:
  
  \begin{displaymath}
    \tilde\Delta_G = |p_{vu}|+|p_{vw}|\geq |p_{vx}|+|p_{vz}| = |p_{xv}|+|p_{vz}|\ge\Delta_G
  \end{displaymath}
   
  For the last inequality we used the fact that since $\Delta_G$ is the length of the shortest path from $x$ to $z$, then every other path (in this case $p'_{xz}$ which is the merge of $p_{xv}$ and $p_{vz}$) has greater or equal length from $p_{x,z}$.
  %$\qed$
\end{proof}

In case we have multiple connected components in $G$, we compute the longest shortest path of each component separately by following the above algorithm.
The connected components can be computed in $O(n+m)$ by using the BFS algorithm.
Let $\tilde\Delta_{G_{1}},\tilde\Delta_{G_{2}}, \ldots , \tilde\Delta_{G_{k}}$ be the approximations of the diameter for each of the $k$ connected components of $G$ as if they were separate graphs.
The output of the approximation for the graph $G$, is the maximum of the values $\tilde\Delta_{G_{1}},\tilde\Delta_{G_{2}}, \ldots , \tilde\Delta_{G_{k}}$.
The time complexity in the case of multiple connected components is again $O(n+m)$ since the sum of the vertices of individual components is $n$ and the sum of edges is $m$. 


The use of the above $2$-approximation algorithm in the computation of the sample size results in at most $c/\varepsilon^2$ more samples than if we have used the exact value $\Delta_G$. 
Furthermore, the computation of $\tilde\Delta_G$ does not affect the running time of our algorithm since for the construction of the first sample we can reuse the already computed shortest paths of $v$ from the approximation of $\Delta_G$.
Specifically, we can sample a new node $u\neq v$ and then choose with uniform probability one of the
(already computed) shortest paths between $v$ and $u$.

\XXX TBD: take care of the weighted case. Say that we can just use $n$ as
approximation and be happy with it. Experiments should show that we are still
faster than Brandes and Pich.

\subsection{High-quality approximation of the top-$k$ betweenness
vertices}\label{sec:topk}
Very often in practice one is interested only in identifying the vertices with
the highest betweenness centrality, as they are the ``primary actors'' in the
network. We present here an algorithm to compute a very high-quality
approximation of the set $T(k,G)$ of the top-$k$ betweenness vertices in a graph
$G=(V,E)$. Formally, let $v_1,\dotsc,v_n$ be a labelling of the vertices in $V$
such that $\betw(v_i)\ge\betw(v_j)$ for $1\le i<j\le n$. Then $T(k,G)$ is
defined as the set of vertices with betweenness at least $\betw(v_k)$:
\[
T(k,G)=\{v\in V ~:~ \betw(v)\ge\betw(v_k)\}\enspace.
\]
Note that $T(k,G)$ may contain more than $k$ vertices. This is in line with the
definition of the set of top-$k$ Frequent Itemsets in the market basket analysis
setting \XXX add reference.

Our algorithm works in two phases. Each phase is basically a run of the
algorithm for approximating the betweenness of all vertices presented in the
previous section, with some additional computation at the end of each phase and
different ways to compute the number of vertices to sample. In the first phase,
we compute a lower bound $\ell'$ to $\betw(v_k)$. In the second phase we use
$\ell'$ to compute the number of samples needed to obtain a relative
$(\ell',\varepsilon)$-approximation to the $(\range_G,\pi_G)$. Then we use this
number of samples to approximate the betweenness of all vertices again, and
return a collection of vertices that is, with high probability, a superset of
$T(k,G)$.

Let $\tilde\Delta_G$ be an upper bound to the vertex-diameter of $G$. Given
$\varepsilon,\delta\in(0,1)$, let $\delta',\delta''$ be two positive reals such
that $(1-\delta')(1-\delta'')\ge(1-\delta)$. Let
\[
  r'=\frac{c}{\varepsilon^2}\left(\lfloor\log_2\tilde\Delta_G\rfloor+1+\log\frac{1}{\delta''}\right)\enspace.
\]
Let $\tilde\betw'_k$ be the $k$-th highest estimated betweenness obtained using
Algorithm~\ref{alg:algorithm} where $r=r'$, and let
\[
  \ell'=\frac{\tilde\betw_k}{n(n-1)}-\varepsilon.
\]
Let
\[
  r''=\frac{c'}{\varepsilon^2\ell}\left(\ell'(\lfloor\log_2\tilde\Delta_G\rfloor+1)+\log\frac{1}{\delta''}\right)\enspace.
\]
We run Algorithm~\ref{alg:algorithm} with $r=r''$ and let $T''(k,G)$ be the set
of the $k$ vertices with the highest estimated betweenness $\tilde\betw''$. Let
$\ell''=\min\{\tilde\betw''(v) / (1+\varepsilon), v\in T''(k,G)\}$. We
return the collection $\tilde T(k,G)$ of vertices $v$ such that
$\tilde\betw''(v)*(1+\varepsilon)/(1-\varepsilon)\ge\ell''$:
\[
\tilde T(k,G)= \left\{v\in V ~:~
\tilde\betw''(v)\frac{1+\varepsilon}{1-\varepsilon}\ge\ell''\right\}\enspace.
\]
The following lemma shows the properties of the collection $\tilde T(k,G)$.

\begin{lemma}
  With probability at least $1-\delta$, $T(k,G)\subseteq \tilde T(k,G)$.
  \XXX add detail about accuracy of estimation?
\end{lemma}
\begin{proof}
  From Thm.~\ref{thm:eapprox} we know that, with probability at least $1-\delta'$, a sample of size $r'$ is a
  $\varepsilon$-approximation to $(\range_G,\pi_G)$ and from
  Thm.~\ref{thm:eapproxrel} we have that with probability at least
  $1-\delta''$ a sample of size $r''$ is a relative
  $(\ell',\varepsilon)$-approximation to $(\range_G,\pi_G)$. Suppose both these events
  occur, which happens with probability at least $1-\delta$.
  Then it is easy to see that $\ell'\le\betw(v_k)$, as there must be at least
  $k$ vertices with exact betweenness greater or equal to $\ell'$. 
  Consider now $\ell''$. Following the same reasoning as for $\ell'$, it should
  be clear that $\ell''\le\betw(v_k)$. The vertices included in $\tilde T(k,G)$
  are all and only those vertices that \emph{may} have exact betweenness at least
  $\ell''$, which implies that all vertices that have exact betweenness at least
  $\betw(v_k)$ are included in $\tilde T(k,G)$. 
\end{proof}

\subsection{Discussion}\label{sec:discussion}
\XXX TBD: running time, worst case, comparison with best previous work.

\citet{BrandesP07} present an algorithm that also uses sampling to approximate
the betweenness centrality of all the vertices of the graph. The algorithm
create a sample $S=\{v_1,\dotsc,v_k\}$ of $k$ vertices drawn uniformly at random 
and computes all the shortest paths between each $v_i$ to all other vertices in
the graph. The estimation $\tilde\betw'(u)$ for the betweenness centrality
$\betw(u)$ is
\[ 
\tilde\betw'(u)= \frac{n}{k}\sum_{v_i\in S}\sum_{w\neq v_i,w\neq
u}\sum_{p\in\mathcal{S}_{v_iw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{v_iw}|},
\]
As it was for our algorithm, the key ingredient to ensure a correct
approximation for the betweenness centrality is the computation of the sample
size $k$. Inspired by the work of~\citet{EppsteinW04}, \citet{BrandesP07} rely
on the following classical result by~\citet{Hoeffding63} for their computation
of $k$.

\begin{theorem}[\citep{Hoeffding63}]
  Let $X_1,X_2,\dotsc,X_k$ be a sequence of independent random variables
  such that $a_i\leq X_i\leq b_i$. Then for any $\xi > 0$
  \begin{equation}\label{eq:hoeffding}
    \Pr\left(\frac{|X_1+\dotsb+X_k|}{k}-\mathbf{E}\left[\frac{|X_1+\dotsb+X_k|}{k}\right]|\geq
    \xi\right)\leq 2e^{-2k^2\xi^2/\sum_{i=1}^{k}(b_{i}-a_{i})^2}\enspace.
  \end{equation}
\end{theorem}

\citet{BrandesP07} use this result to compute a sample size $k$ sufficient to ensure that, for
a fixed vertex $u$,
\[ 
\Pr\left(|\betw(u)-\tilde\betw'(u)|>\varepsilon n(n-1)\right)<\frac{\delta}{n}\enspace.
\]
In their setting $\xi=\varepsilon n(n-1)$ and there is a variable $X_i$ for
each vertex $v_i$ in the sample:
\[ 
X_i=n\sum_{w\neq v_i,w\neq
u}\sum_{p\in\mathcal{S}_{v_iw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{v_iw}|}\enspace
.
\]
It is easy to see that $0\le X_i\le n(n-2)$. Moreover,
\begin{align*}
\mathbf{E}\left[\frac{|X_1+\dotsb+X_k|}{k}\right] &=
\frac{n}{k}\mathbf{E}\left[\sum_{v_i\in S}\sum_{w\neq v_i,w\neq
u}\sum_{p\in\mathcal{S}_{v_iw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{v_iw}|}\right]
=\frac{n}{k}\sum_{v\in V}\mathbf{E}\left[Y_v\sum_{w\neq v,w\neq
u}\sum_{p\in\mathcal{S}_{vw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{vw}|}\right] =
\\
&=\frac{n}{k}\sum_{v\in V}\mathbf{E}[Y_v]\sum_{w\neq v,w\neq
u}\sum_{p\in\mathcal{S}_{vw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{vw}|}
=\frac{n}{k}\sum_{v\in V}\frac{k}{n}\sum_{w\neq v,w\neq
u}\sum_{p\in\mathcal{S}_{vw}}\frac{\mathds{1}_{\mathsf{Int}(p)}(u)}{|\mathcal{S}_{vw}|}
= \betw(u),
\end{align*}
where $Y_v$ is a Bernoulli random variable taking value 1 if $v\in S$, and 0
otherwise, so $\Pr(Y_v=1)=k/n$.

Plugging these values in~\eqref{eq:hoeffding}, we have
\[
\Pr\left(|\betw(u)-\tilde\betw'(u)|>\varepsilon n(n-1)\right)\leq
2e^{-2(k\varepsilon n(n-1))^2/kn^2(n-2)^2}=2e^{-2k\epsilon^2(n-1)^2/(n-2)^2}\enspace.
\]
We want this probability to be at most $\delta/n$, so we need a sample of size
\[
k\geq \frac{(n-2)^2}{2\varepsilon^2(n-1)^2}\left(\ln n
+\ln\frac{1}{\delta} +\ln 2\right)\enspace.
\]
An application of the union bound over the $n$ vertices ensures a uniform guarantee on the quality of
all the estimation, with probability at least $1-\delta$.

